{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NumPy\n",
    "_(ejemplos probados en la versión 1.17.2)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.17.2'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy import linalg\n",
    "\n",
    "np.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3]\n",
      "2\n",
      "[[1 2 3]\n",
      " [0 1 4]\n",
      " [5 6 0]]\n",
      "6\n",
      "[16 22 11]\n",
      "[[-24.  18.   5.]\n",
      " [ 20. -15.  -4.]\n",
      " [ -5.   4.   1.]]\n",
      "[[ 1.00000000e+00 -1.77635684e-15 -4.44089210e-16]\n",
      " [ 0.00000000e+00  1.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  1.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "# Ejemplo mínimo de NumPy\n",
    "\n",
    "v = np.array([1,2,3])\n",
    "print(v)\n",
    "print(v[1])\n",
    "\n",
    "m = np.array([[1,2,3],[0,1,4],[5,6,0]])\n",
    "print(m)\n",
    "print(m[2,1])\n",
    "\n",
    "# Multiplicación vector-matriz\n",
    "print(v @ m)\n",
    "\n",
    "# Inversa de una matriz\n",
    "m_inv = linalg.inv(m)\n",
    "print(m_inv)\n",
    "\n",
    "# Multiplicación matriz-matriz\n",
    "print(m @ m_inv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas\n",
    "_(ejemplos probados en la versión 0.25.1)_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga desde fichero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.25.1'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga el fichero \n",
    "df = pd.read_csv('../../data/Cap5/titanic.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Asociación  Importe total  Importe justificado  Restante\n",
      "0          AMPA ANTONIO MACHADO        2344.99                    0  -2344.99\n",
      "1   AMPA BACHILLER ALONSO LOPEZ        3200.00                    0  -3200.00\n",
      "2                 AMPA CASTILLA        2604.44                    0  -2604.44\n",
      "3          AMPA DAOIZ Y VELARDE        3152.74                    0  -3152.74\n",
      "4            AMPA EMILIO CASADO        3015.67                    0  -3015.67\n",
      "5    AMPA FEDERICO GARCIA LORCA        1919.06                    0  -1919.06\n",
      "6          AMPA GABRIEL Y GALAN        2741.51                    0  -2741.51\n",
      "7              AMPA LUIS BUÑUEL        2081.00                    0  -2081.00\n",
      "8         AMPA MIGUEL HERNANDEZ        2923.35                    0  -2923.35\n",
      "9               AMPA MIRAFLORES        2787.21                    0  -2787.21\n",
      "10         AMPA PARQUE CATALUÑA        2604.44                    0  -2604.44\n",
      "11  AMPA PROFESOR TIERNO GALVÁN        1286.00                    0  -1286.00\n",
      "12       AMPA SEIS DE DICIEMBRE        1950.00                    0  -1950.00\n",
      "13            AMPA VALDEPALITOS        3929.50                    0  -3929.50\n",
      "14              AMPA LA CHOPERA        1430.00                    0  -1430.00\n",
      "15             AMPA EL CUQUILLO        1507.83                    0  -1507.83\n",
      "16            AMPA VALDELAPARRA        2465.00                    0  -2465.00\n",
      "17                AMPA RIVENDEL        2200.00                    0  -2200.00\n",
      "18                   AMPA AGORA        2421.67                    0  -2421.67\n",
      "19               AMPA ALDEBARAN        3107.05                    0  -3107.05\n",
      "20       AMPA GINER DE LOS RIOS        2058.00                    0  -2058.00\n",
      "21            AMPA SEVERO OCHOA        3563.97                    0  -3563.97\n",
      "22        AMPA VIRGEN DE LA PAZ        1416.45                    0  -1416.45\n",
      "23              AMPA JUAN XXIII        1781.98                    0  -1781.98\n",
      "24             AMPA SAN ANTONIO        2101.83                    0  -2101.83\n",
      "25         AMPA PADRE  MANYANET        2695.82                    0  -2695.82\n",
      "26                    AMPA FAPA        3198.43                    0  -3198.43\n"
     ]
    }
   ],
   "source": [
    "# Lectura de todas las hojas de 'data/Cap5/subvenciones_totales.xls', devuelve un diccionario ordenado (str, DataFrame)\n",
    "subvenciones = pd.read_excel('../../data/Cap5/subvenciones_totales.xls', sheet_name=None)\n",
    "print(subvenciones['Totales'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizar y extraer información"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>886</td>\n",
       "      <td>887</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Montvila, Rev. Juozas</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>211536</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>887</td>\n",
       "      <td>888</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Graham, Miss. Margaret Edith</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112053</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>B42</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>888</td>\n",
       "      <td>889</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>W./C. 6607</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>889</td>\n",
       "      <td>890</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Behr, Mr. Karl Howell</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>111369</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>C148</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>890</td>\n",
       "      <td>891</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Dooley, Mr. Patrick</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>370376</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass  \\\n",
       "0              1         0       3   \n",
       "1              2         1       1   \n",
       "2              3         1       3   \n",
       "3              4         1       1   \n",
       "4              5         0       3   \n",
       "..           ...       ...     ...   \n",
       "886          887         0       2   \n",
       "887          888         1       1   \n",
       "888          889         0       3   \n",
       "889          890         1       1   \n",
       "890          891         0       3   \n",
       "\n",
       "                                                  Name     Sex   Age  SibSp  \\\n",
       "0                              Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1    Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                               Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3         Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                             Allen, Mr. William Henry    male  35.0      0   \n",
       "..                                                 ...     ...   ...    ...   \n",
       "886                              Montvila, Rev. Juozas    male  27.0      0   \n",
       "887                       Graham, Miss. Margaret Edith  female  19.0      0   \n",
       "888           Johnston, Miss. Catherine Helen \"Carrie\"  female   NaN      1   \n",
       "889                              Behr, Mr. Karl Howell    male  26.0      0   \n",
       "890                                Dooley, Mr. Patrick    male  32.0      0   \n",
       "\n",
       "     Parch            Ticket     Fare Cabin Embarked  \n",
       "0        0         A/5 21171   7.2500   NaN        S  \n",
       "1        0          PC 17599  71.2833   C85        C  \n",
       "2        0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3        0            113803  53.1000  C123        S  \n",
       "4        0            373450   8.0500   NaN        S  \n",
       "..     ...               ...      ...   ...      ...  \n",
       "886      0            211536  13.0000   NaN        S  \n",
       "887      0            112053  30.0000   B42        S  \n",
       "888      2        W./C. 6607  23.4500   NaN        S  \n",
       "889      0            111369  30.0000  C148        C  \n",
       "890      0            370376   7.7500   NaN        Q  \n",
       "\n",
       "[891 rows x 12 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualizar el principio y final de un DataFrame\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     PassengerId  Survived  Pclass  \\\n",
      "0              1         0       3   \n",
      "1              2         1       1   \n",
      "2              3         1       3   \n",
      "3              4         1       1   \n",
      "4              5         0       3   \n",
      "..           ...       ...     ...   \n",
      "886          887         0       2   \n",
      "887          888         1       1   \n",
      "888          889         0       3   \n",
      "889          890         1       1   \n",
      "890          891         0       3   \n",
      "\n",
      "                                                  Name     Sex   Age  SibSp  \\\n",
      "0                              Braund, Mr. Owen Harris    male  22.0      1   \n",
      "1    Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
      "2                               Heikkinen, Miss. Laina  female  26.0      0   \n",
      "3         Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
      "4                             Allen, Mr. William Henry    male  35.0      0   \n",
      "..                                                 ...     ...   ...    ...   \n",
      "886                              Montvila, Rev. Juozas    male  27.0      0   \n",
      "887                       Graham, Miss. Margaret Edith  female  19.0      0   \n",
      "888           Johnston, Miss. Catherine Helen \"Carrie\"  female   NaN      1   \n",
      "889                              Behr, Mr. Karl Howell    male  26.0      0   \n",
      "890                                Dooley, Mr. Patrick    male  32.0      0   \n",
      "\n",
      "     Parch            Ticket     Fare Cabin Embarked  \n",
      "0        0         A/5 21171   7.2500   NaN        S  \n",
      "1        0          PC 17599  71.2833   C85        C  \n",
      "2        0  STON/O2. 3101282   7.9250   NaN        S  \n",
      "3        0            113803  53.1000  C123        S  \n",
      "4        0            373450   8.0500   NaN        S  \n",
      "..     ...               ...      ...   ...      ...  \n",
      "886      0            211536  13.0000   NaN        S  \n",
      "887      0            112053  30.0000   B42        S  \n",
      "888      2        W./C. 6607  23.4500   NaN        S  \n",
      "889      0            111369  30.0000  C148        C  \n",
      "890      0            370376   7.7500   NaN        Q  \n",
      "\n",
      "[891 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "# Mostrar el principio y final de un DataFrame, en modo texto\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n",
       "       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Índice pandas con las columnas de un DataFrame\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 12)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tamaño de un DataFrame\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.indexing._iLocIndexer'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PassengerId                   6\n",
       "Survived                      0\n",
       "Pclass                        3\n",
       "Name           Moran, Mr. James\n",
       "Sex                        male\n",
       "Age                         NaN\n",
       "SibSp                         0\n",
       "Parch                         0\n",
       "Ticket                   330877\n",
       "Fare                     8.4583\n",
       "Cabin                       NaN\n",
       "Embarked                      Q\n",
       "Name: 5, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "\n",
       "   Parch     Ticket     Fare Cabin Embarked  \n",
       "0      0  A/5 21171   7.2500   NaN        S  \n",
       "1      0   PC 17599  71.2833   C85        C  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>Sandstrom, Miss. Marguerite Rut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>Saundercock, Mr. William Henry</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Name\n",
       "0           Braund, Mr. Owen Harris\n",
       "10  Sandstrom, Miss. Marguerite Rut\n",
       "12   Saundercock, Mr. William Henry"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# .iloc para seleccionar por posición\n",
    "print(type(df.iloc))\n",
    "display(df.iloc[5])   # Fila en la posición 5\n",
    "display(df.iloc[:2])  # Filas en el rango [0,2)\n",
    "display(df.iloc[0,0]) # Celda (0,0)\n",
    "display(df.iloc[[0,10,12],3:4]) # Filas 0, 10 y 12, columnas 3:4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.indexing._LocIndexer'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PassengerId                          1\n",
       "Survived                             0\n",
       "Pclass                               3\n",
       "Name           Braund, Mr. Owen Harris\n",
       "Sex                               male\n",
       "Age                                 22\n",
       "SibSp                                1\n",
       "Parch                                0\n",
       "Ticket                       A/5 21171\n",
       "Fare                              7.25\n",
       "Cabin                              NaN\n",
       "Embarked                             S\n",
       "Name: 0, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "7.25"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Sex   Age  SibSp  Parch            Ticket     Fare\n",
       "0    male  22.0      1      0         A/5 21171   7.2500\n",
       "1  female  38.0      1      0          PC 17599  71.2833\n",
       "2  female  26.0      0      0  STON/O2. 3101282   7.9250\n",
       "3  female  35.0      1      0            113803  53.1000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>female</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Sex     Fare Embarked\n",
       "0    male   7.2500        S\n",
       "1  female  71.2833        C\n",
       "2  female   7.9250        S\n",
       "3  female  53.1000        S"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Goldschmidt, Mr. George B</td>\n",
       "      <td>male</td>\n",
       "      <td>71.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17754</td>\n",
       "      <td>34.6542</td>\n",
       "      <td>A5</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>116</td>\n",
       "      <td>117</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Connors, Mr. Patrick</td>\n",
       "      <td>male</td>\n",
       "      <td>70.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>370369</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>493</td>\n",
       "      <td>494</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Artagaveytia, Mr. Ramon</td>\n",
       "      <td>male</td>\n",
       "      <td>71.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17609</td>\n",
       "      <td>49.5042</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>630</td>\n",
       "      <td>631</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Barkworth, Mr. Algernon Henry Wilson</td>\n",
       "      <td>male</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27042</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>A23</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>851</td>\n",
       "      <td>852</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Svensson, Mr. Johan</td>\n",
       "      <td>male</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>347060</td>\n",
       "      <td>7.7750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass                                  Name  \\\n",
       "96            97         0       1             Goldschmidt, Mr. George B   \n",
       "116          117         0       3                  Connors, Mr. Patrick   \n",
       "493          494         0       1               Artagaveytia, Mr. Ramon   \n",
       "630          631         1       1  Barkworth, Mr. Algernon Henry Wilson   \n",
       "851          852         0       3                   Svensson, Mr. Johan   \n",
       "\n",
       "      Sex   Age  SibSp  Parch    Ticket     Fare Cabin Embarked  \n",
       "96   male  71.0      0      0  PC 17754  34.6542    A5        C  \n",
       "116  male  70.5      0      0    370369   7.7500   NaN        Q  \n",
       "493  male  71.0      0      0  PC 17609  49.5042   NaN        C  \n",
       "630  male  80.0      0      0     27042  30.0000   A23        S  \n",
       "851  male  74.0      0      0    347060   7.7750   NaN        S  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>71.0</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>116</td>\n",
       "      <td>70.5</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>493</td>\n",
       "      <td>71.0</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>630</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>851</td>\n",
       "      <td>74.0</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Age   Sex\n",
       "96   71.0  male\n",
       "116  70.5  male\n",
       "493  71.0  male\n",
       "630  80.0  male\n",
       "851  74.0  male"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# .iloc para seleccionar usando los índices\n",
    "print(type(df.loc))\n",
    "display(df.loc[0])                # Fila con índice 0\n",
    "display(df.loc[0,'Fare'])         # celda de la fila 0 y columna 'Fare'\n",
    "display(df.loc[:3, 'Sex':'Fare']) # Filas 0:3 (incluidas) en las columnas 'Sex':'Fare' (incluidas)\n",
    "display(df.loc[:3, ['Sex','Fare','Embarked']]) # Filas 0:3 (incluidas) en las columnas 'Sex','Fare' y 'Embarked'\n",
    "display(df.loc[df['Age']> 70])    # Filas con 'Age' > 70\n",
    "display(df.loc[df['Age']> 70, ['Age','Sex']])    # Filas con 'Age' > 70, mostrar la columna 'Sex'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      int64\n",
       "Survived         int64\n",
       "Pclass           int64\n",
       "Name            object\n",
       "Sex             object\n",
       "Age            float64\n",
       "SibSp            int64\n",
       "Parch            int64\n",
       "Ticket          object\n",
       "Fare           float64\n",
       "Cabin           object\n",
       "Embarked        object\n",
       "dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tipos almacenados en cada columna\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        PassengerId    Survived      Pclass                 Name   Sex  \\\n",
      "count    891.000000  891.000000  891.000000                  891   891   \n",
      "unique          NaN         NaN         NaN                  891     2   \n",
      "top             NaN         NaN         NaN  Murdlin, Mr. Joseph  male   \n",
      "freq            NaN         NaN         NaN                    1   577   \n",
      "mean     446.000000    0.383838    2.308642                  NaN   NaN   \n",
      "std      257.353842    0.486592    0.836071                  NaN   NaN   \n",
      "min        1.000000    0.000000    1.000000                  NaN   NaN   \n",
      "25%      223.500000    0.000000    2.000000                  NaN   NaN   \n",
      "50%      446.000000    0.000000    3.000000                  NaN   NaN   \n",
      "75%      668.500000    1.000000    3.000000                  NaN   NaN   \n",
      "max      891.000000    1.000000    3.000000                  NaN   NaN   \n",
      "\n",
      "               Age       SibSp       Parch    Ticket        Fare Cabin  \\\n",
      "count   714.000000  891.000000  891.000000       891  891.000000   204   \n",
      "unique         NaN         NaN         NaN       681         NaN   147   \n",
      "top            NaN         NaN         NaN  CA. 2343         NaN    G6   \n",
      "freq           NaN         NaN         NaN         7         NaN     4   \n",
      "mean     29.699118    0.523008    0.381594       NaN   32.204208   NaN   \n",
      "std      14.526497    1.102743    0.806057       NaN   49.693429   NaN   \n",
      "min       0.420000    0.000000    0.000000       NaN    0.000000   NaN   \n",
      "25%      20.125000    0.000000    0.000000       NaN    7.910400   NaN   \n",
      "50%      28.000000    0.000000    0.000000       NaN   14.454200   NaN   \n",
      "75%      38.000000    1.000000    0.000000       NaN   31.000000   NaN   \n",
      "max      80.000000    8.000000    6.000000       NaN  512.329200   NaN   \n",
      "\n",
      "       Embarked  \n",
      "count       889  \n",
      "unique        3  \n",
      "top           S  \n",
      "freq        644  \n",
      "mean        NaN  \n",
      "std         NaN  \n",
      "min         NaN  \n",
      "25%         NaN  \n",
      "50%         NaN  \n",
      "75%         NaN  \n",
      "max         NaN  \n"
     ]
    }
   ],
   "source": [
    "# Descripción de los valores de un DataFrame\n",
    "print(df.describe(include='all'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values [PassengerId]: 0\n",
      "Missing values [Survived]: 0\n",
      "Missing values [Pclass]: 0\n",
      "Missing values [Name]: 0\n",
      "Missing values [Sex]: 0\n",
      "Missing values [Age]: 177\n",
      "Missing values [SibSp]: 0\n",
      "Missing values [Parch]: 0\n",
      "Missing values [Ticket]: 0\n",
      "Missing values [Fare]: 0\n",
      "Missing values [Cabin]: 687\n",
      "Missing values [Embarked]: 2\n",
      "\n",
      "Unique values [PassengerId]: 891\n",
      "Unique values [Survived]: 2\n",
      "Unique values [Pclass]: 3\n",
      "Unique values [Name]: 891\n",
      "Unique values [Sex]: 2\n",
      "Unique values [Age]: 89\n",
      "Unique values [SibSp]: 7\n",
      "Unique values [Parch]: 7\n",
      "Unique values [Ticket]: 681\n",
      "Unique values [Fare]: 248\n",
      "Unique values [Cabin]: 148\n",
      "Unique values [Embarked]: 4\n"
     ]
    }
   ],
   "source": [
    "# Código alternativo para calcular valores nulos y únicos\n",
    "\n",
    "# Valores nulos\n",
    "for c in df.columns:\n",
    "    print(\"Missing values [{0}]:\".format(c), df[c].isna().sum())\n",
    "print()\n",
    "\n",
    "# Valores únicos    \n",
    "for c in df.columns:\n",
    "    print(\"Unique values [{0}]:\".format(c), df[c].unique().size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformar DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>885</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>29.1250</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>886</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>887</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>889</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>890</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>712 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Survived  Pclass  Sex   Age  SibSp  Parch     Fare  Embarked\n",
       "0           0       3    1  22.0      1      0   7.2500         2\n",
       "1           1       1    0  38.0      1      0  71.2833         0\n",
       "2           1       3    0  26.0      0      0   7.9250         2\n",
       "3           1       1    0  35.0      1      0  53.1000         2\n",
       "4           0       3    1  35.0      0      0   8.0500         2\n",
       "..        ...     ...  ...   ...    ...    ...      ...       ...\n",
       "885         0       3    0  39.0      0      5  29.1250         1\n",
       "886         0       2    1  27.0      0      0  13.0000         2\n",
       "887         1       1    0  19.0      0      0  30.0000         2\n",
       "889         1       1    1  26.0      0      0  30.0000         0\n",
       "890         0       3    1  32.0      0      0   7.7500         1\n",
       "\n",
       "[712 rows x 8 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Carga el fichero \n",
    "df = pd.read_csv('../../data/Cap5/titanic.csv')\n",
    "\n",
    "# Elimina columnas no relevantes y filas con valores nulos\n",
    "df = df.drop(columns=['PassengerId', 'Name', 'Ticket','Cabin'])\n",
    "df = df.dropna()\n",
    "\n",
    "# Traduce los valores categóricos de 'Sex' y 'Embarked' a número enteros\n",
    "df['Sex'] = df['Sex'].astype('category').cat.codes\n",
    "df['Embarked'] = df['Embarked'].astype('category').cat.codes\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Salvar a ficheros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A formato CSV\n",
    "df.to_csv('../../data/Cap5/titanic_ml.csv', index=False)\n",
    "\n",
    "# A formato Excel (XLS y XLSX)\n",
    "# La hoja se llamará 'Sheet1'\n",
    "df.to_excel('../../data/Cap5/titanic_ml.xls', index=False)\n",
    "df.to_excel('../../data/Cap5/titanic_ml.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insertar varias hojas en un fichero Excel\n",
    "writer = pd.ExcelWriter('../../data/Cap5/titanic_2.xlsx')\n",
    "df.to_excel(writer, sheet_name='Hoja 1', index=False)\n",
    "df.to_excel(writer, sheet_name='Hoja 2', index=False)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aprendizaje automático con Scikit-learn\n",
    "_(ejemplos probados en la versión 0.21.3)_\n",
    "\n",
    "**IMPORTANTE**: el código de los ejemplos de Scikit-learn que aparecen en el libro está realizado y probado en la versión **0.19.2** de Scikit-learn. Con el paso del tiempo, algunos apartados han dejado de funcionar en versiones superiores. Por ello, hemos actualizado este _notebook_ para que funcione correctamente con Scikit-learn versión 0.21.3.\n",
    "\n",
    "Los principales cambios han sido:\n",
    " * Incorporar el transformador `OneHotEncoder` dentro de un `ColumnTransformer` para codificar únicamente la columna `'Embarked'`. El parámetro `categorical_features` se había quedado obsoleto. \n",
    " * Inclusión de algunos parámetros a los clasificadores en lugar de usar valores por defecto, para evitar avisos de Scikit-learn porque el valor por defecto ha cambiado en la nueva versión. Concretamente, hemos añadido `gamma='scale'` en `SVC` y `cv=3` en `GridSearchCV`.\n",
    " * Corrección de la función `calinski_harabasz_score` (el nombre tenía una errata en la versión 0.19.2).\n",
    " * Inclusión directa de `joblib` con `import joblib` en lugar de usar `sklearn.externals`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.21.3'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Versión de scikit-learn\n",
    "import sklearn\n",
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocesado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para partir un DataFrame en train+test y separar también la columna clase\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def split_label(df, test_size, label):\n",
    "    train, test = train_test_split(df, test_size=test_size)\n",
    "    features = df.columns.drop(label)\n",
    "    train_X = train[features]\n",
    "    train_y = train[label]\n",
    "    test_X = test[features]\n",
    "    test_y = test[label]\n",
    "    \n",
    "    return train_X, train_y, test_X, test_y   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# División en train (80%) y test (20%) para clasificación, con clase 'Survived'\n",
    "titanic = pd.read_csv('../../data/Cap5/titanic_ml.csv')\n",
    "train_X, train_y, test_X, test_y = split_label(titanic, 0.2, 'Survived')\n",
    "\n",
    "# train_X y test_X son DataFrames\n",
    "# train_y y test_y son Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(569, 9)\n",
      "float64\n",
      "[[  0.       0.       1.     ...   0.       0.      26.55  ]\n",
      " [  0.       0.       1.     ...   0.       0.      13.5   ]\n",
      " [  0.       0.       1.     ...   2.       0.     133.65  ]\n",
      " ...\n",
      " [  0.       1.       0.     ...   0.       0.       7.7333]\n",
      " [  0.       0.       1.     ...   0.       0.       7.25  ]\n",
      " [  0.       0.       1.     ...   0.       0.      10.5   ]]\n"
     ]
    }
   ],
   "source": [
    "# One hot encoding de la columna 'Embarked'   \n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Aplica el transformador OneHotEncoder a la columna 'Embarked', dejando el resto sin \n",
    "# modificar ('passthrough'). Detecta automáticamente el número de categorías diferentes\n",
    "ohe = ColumnTransformer( [(\"embarked_ohe\", OneHotEncoder(categories='auto'), ['Embarked'])], \n",
    "                         remainder='passthrough')\n",
    "train_X_1 = ohe.fit_transform(train_X)\n",
    "\n",
    "# train_X_1 es un objeto ndarray de tamaño (569, 9) y tipo float64\n",
    "print(type(train_X_1))\n",
    "print(train_X_1.shape)\n",
    "print(train_X_1.dtype)\n",
    "print(train_X_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(569, 9)\n",
      "float64\n",
      "[0.         0.         1.         0.         1.         0.63558683\n",
      " 0.         0.         0.05182215]\n",
      "[0.         0.         1.         0.5        1.         0.34656949\n",
      " 0.         0.         0.02635025]\n",
      "[0.         0.         1.         0.         1.         0.62302086\n",
      " 0.4        0.         0.26086743]\n"
     ]
    }
   ],
   "source": [
    "# Escalado al rango [0,1] de todos los atributos\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "min_max_scaler = MinMaxScaler()\n",
    "train_X_2 = min_max_scaler.fit_transform(train_X_1)\n",
    "\n",
    "print(type(train_X_2))\n",
    "print(train_X_2.shape)\n",
    "print(train_X_2.dtype)\n",
    "\n",
    "# Muestra las 3 primeras entradas de train_X_2\n",
    "for i in range(3): \n",
    "    print(train_X_2[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clasificación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(143, 7)\n",
      "(143, 9)\n",
      "Precisión sobre test: 0.7692307692307693\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1,\n",
       "       0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Entrenamiento\n",
    "clf = SVC(gamma='scale')\n",
    "clf.fit(train_X_2, train_y)\n",
    "\n",
    "# Transformación del conjunto de test (one hot encoding y escalado)\n",
    "print(test_X.shape)\n",
    "test_X_2 = min_max_scaler.transform(ohe.transform(test_X))\n",
    "print(test_X_2.shape)\n",
    "\n",
    "# Evaluación del modelo mediante precisión\n",
    "print(\"Precisión sobre test:\", clf.score(test_X_2, test_y)) \n",
    "\n",
    "# Uso del modelo\n",
    "clf.predict(test_X_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión sobre test: 0.7762237762237763\n"
     ]
    }
   ],
   "source": [
    "# Clasificación usando kNN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "clf = KNeighborsClassifier()\n",
    "clf.fit(train_X_2, train_y)\n",
    "\n",
    "# Evaluación del modelo mediante precisión\n",
    "print(\"Precisión sobre test:\", clf.score(test_X_2, test_y)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regresión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2: 0.3738168113393807\n",
      "MSE: 2825.4236072676895\n",
      "MAE: 24.850258962773328\n"
     ]
    }
   ],
   "source": [
    "# Regresión lineal\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "# separación train-test con clase 'Fare'\n",
    "titanic = pd.read_csv('../../data/Cap5/titanic_ml.csv')\n",
    "train_X, train_y, test_X, test_y = split_label(titanic, 0.2, 'Fare')\n",
    "\n",
    "# one hot encoding\n",
    "index_Embarked = train_X.columns.get_loc('Embarked')\n",
    "ohe = ColumnTransformer( [(\"embarked_ohe\", OneHotEncoder(categories='auto'), ['Embarked'])], \n",
    "                         remainder='passthrough')\n",
    "train_X_1 = ohe.fit_transform(train_X)\n",
    "\n",
    "# Escalado de atributos al rango [0,1]\n",
    "min_max_scaler = MinMaxScaler()\n",
    "train_X_2 = min_max_scaler.fit_transform(train_X_1)\n",
    "\n",
    "# Entrenamiento\n",
    "reg = LinearRegression()\n",
    "reg.fit(train_X_2, train_y)\n",
    "\n",
    "# Transformación del conjunto de test (one hot encoding y escalado)\n",
    "test_X_2 = min_max_scaler.transform(ohe.transform(test_X))\n",
    "\n",
    "# Evaluación del modelo mediante métrica R^2 y MSE\n",
    "print(\"R^2:\", reg.score(test_X_2, test_y)) \n",
    "\n",
    "# Uso y evaluación del modelo con MSE\n",
    "pred = reg.predict(test_X_2)\n",
    "print(\"MSE:\", mean_squared_error(test_y, pred))\n",
    "print(\"MAE:\", mean_absolute_error(test_y, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2: 0.3738168113393807\n",
      "MSE: 2825.4236072676895\n",
      "MAE: 24.850258962773328\n"
     ]
    }
   ],
   "source": [
    "# Regresión usando kNN\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "reg = LinearRegression()\n",
    "reg.fit(train_X_2, train_y)\n",
    "\n",
    "# Evaluación del modelo mediante métrica R^2\n",
    "print(\"R^2:\", reg.score(test_X_2, test_y)) \n",
    "\n",
    "# Uso y evaluación del modelo con MSE y MAE\n",
    "pred = reg.predict(test_X_2)\n",
    "print(\"MSE:\", mean_squared_error(test_y, pred))\n",
    "print(\"MAE:\", mean_absolute_error(test_y, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Centros de los clústeres:\n",
      " [[ 1.00000000e+00 -9.02056208e-17  1.22124533e-15  6.07692308e-01\n",
      "   3.73076923e-01  5.30769231e-01  3.81939799e-01  8.46153846e-02\n",
      "   6.92307692e-02  1.33306411e-01]\n",
      " [ 3.33066907e-16  3.79146919e-02  9.62085308e-01  9.90521327e-01\n",
      "   4.95260664e-01  3.27014218e-01  3.43576883e-01  9.95260664e-02\n",
      "   9.47867299e-02  7.78150129e-02]\n",
      " [ 1.22124533e-15  5.39083558e-02  9.46091644e-01 -2.60902411e-15\n",
      "   7.77628032e-01  8.49056604e-01  3.75477998e-01  1.11051213e-01\n",
      "   6.01976640e-02  3.85185852e-02]]\n",
      "silhouette_score: 0.4036033588295353\n",
      "calinski_harabasz: 369.21898121397425\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.73984874, 1.31150832, 0.31789029],\n",
       "       [0.77530662, 1.52274362, 2.0626726 ],\n",
       "       [1.69060722, 0.62284202, 1.33998748],\n",
       "       ...,\n",
       "       [1.6169074 , 0.62174709, 1.53881024],\n",
       "       [0.73107457, 1.62637004, 1.88275404],\n",
       "       [1.73454341, 1.88829988, 1.37090166]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score, calinski_harabasz_score\n",
    "\n",
    "titanic = pd.read_csv('../../data/Cap5/titanic_ml.csv')\n",
    "\n",
    "# one hot encoding\n",
    "ohe = ColumnTransformer( [(\"embarked_ohe\", OneHotEncoder(categories='auto'), ['Embarked'])], \n",
    "                         remainder='passthrough')\n",
    "titanic_1 = ohe.fit_transform(titanic)\n",
    "\n",
    "# Escalado de atributos al rango [0,1]\n",
    "min_max_scaler = MinMaxScaler()\n",
    "titanic_2 = min_max_scaler.fit_transform(titanic_1)\n",
    "\n",
    "# Clustering\n",
    "clu = KMeans(n_clusters=3)\n",
    "clu.fit(titanic_2)\n",
    "print(\"Centros de los clústeres:\\n\", clu.cluster_centers_)\n",
    "\n",
    "# Evaluación de los clústeres\n",
    "print('silhouette_score:', silhouette_score(titanic_2, clu.labels_))\n",
    "print('calinski_harabasz:', calinski_harabasz_score(titanic_2, clu.labels_))\n",
    "\n",
    "# Comprobar distancia a cada centroide para las instancias de titanic_2 (podrían ser otro conjunto de datos)\n",
    "clu.transform(titanic_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clasificación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precisión: 0.7692307692307693\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1,\n",
       "       0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "       1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0,\n",
       "       1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0,\n",
       "       1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "## Preprocesado\n",
    "\n",
    "# División en train (80%) y test (20%) para clasificación, con clase 'Survived'\n",
    "titanic = pd.read_csv('../../data/Cap5/titanic_ml.csv')\n",
    "train_X, train_y, test_X, test_y = split_label(titanic, 0.2, 'Survived')\n",
    "\n",
    "# Etapa one hot encoding\n",
    "ohe = ColumnTransformer( [(\"embarked_ohe\", OneHotEncoder(categories='auto'), ['Embarked'])], \n",
    "                         remainder='passthrough')\n",
    "\n",
    "# Etapa de escalado de atributos al rango [0,1]\n",
    "min_max_scaler = MinMaxScaler()\n",
    "\n",
    "# Etapa de clasificación\n",
    "svm = SVC(gamma='scale')\n",
    "\n",
    "# Creación del pipeline\n",
    "pipe = Pipeline([('ohe', ohe), ('sca', min_max_scaler), ('clf', svm)])\n",
    "\n",
    "# Entranamiento del pipeline\n",
    "pipe.fit(train_X, train_y)\n",
    "\n",
    "# Evaluación del pipeline\n",
    "print('precisión:', pipe.score(test_X, test_y))\n",
    "\n",
    "# Uso del modelo\n",
    "pipe.predict(test_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regresión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2: 0.3893287363956175\n",
      "[ 84.27053245  13.29083814  -4.33683689  -5.87755814  -1.57114046\n",
      "   9.64555881  61.8735344    5.90045127  -2.53081142   5.27277225\n",
      " 114.79421544   9.79340235  -1.73108562  -1.57114046  35.44915073\n",
      "  -2.85070173  -1.57114046  81.71006746  97.3731143   30.05684607\n",
      "  64.95010466  29.57701059  -4.77004365  -3.17059205  -1.73108562\n",
      "  27.49772352  84.39701828  55.56930432  -2.37086626  -2.37086626\n",
      "  25.41843645   4.47304646  34.6016794   70.66229964  -4.45015333\n",
      "  31.24283106  56.08675203  -2.2109211   38.26361376  83.95064213\n",
      "   2.16186546  51.75063576  28.13750416  93.34157578  71.30208028\n",
      "  54.96164057  89.42168709  30.15336351  13.67068577  60.56521649\n",
      "  30.05684607  -5.71761298  32.25024755  -0.93135982  65.96962277\n",
      "  87.32094364  65.5898853   -1.57114046  13.29083814  89.44170236\n",
      "  -1.73108562  34.10974231  87.50234518   1.84197514  -1.57114046\n",
      "  58.565902    -1.73108562  41.73690066  68.35669854   0.57451548\n",
      "  -1.89103078  41.41701034  93.90015155  41.75659177  52.00709836\n",
      "   2.17396708  16.14983574  64.15037887  30.76374197  30.37673639\n",
      "  40.78160824  79.79206799  15.99506985  80.36547976  -0.93135982\n",
      "  57.8582504   30.38883801  75.57476883   1.37424128   2.3004529\n",
      "  29.41706543   4.73308962  28.29744932  25.73832677  -6.36949524\n",
      "  -1.4111953   92.32016543  60.09748263  -2.37086626  65.11004982\n",
      "  27.977559    -2.05097594  33.40653395  -3.63832591  -1.25125014\n",
      "  -0.41818049  -8.12889199  55.00949626  14.42255587  41.03239532\n",
      "  12.09248173   1.85407676  55.40935916  78.45823946  30.85657187\n",
      "  23.78137263  95.62608897  -3.79827107  22.4419642    5.26067063\n",
      "  -1.09130498  25.41843645  25.09854613  46.42707403  46.69032304\n",
      "  48.07581529  -2.85070173  86.48840697  -3.81037269  -0.93135982\n",
      "  84.3303796   30.85657187  29.25712027  75.89911692  -0.93135982\n",
      "  68.36880016  -2.2109211   32.84228265   2.01402192  16.14983574\n",
      "  -2.53081142  35.38572301  82.35119054]\n",
      "MSE: 2553.931542559366\n",
      "MAE: 24.15379162442633\n"
     ]
    }
   ],
   "source": [
    "# Pipeline para regresión\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "## Preprocesado\n",
    "\n",
    "# División en train (80%) y test (20%) para clasificación, con clase 'Fare'\n",
    "titanic = pd.read_csv('../../data/Cap5/titanic_ml.csv')\n",
    "train_X, train_y, test_X, test_y = split_label(titanic, 0.2, 'Fare')\n",
    "\n",
    "# Etapa de one hot encoding\n",
    "ohe = ColumnTransformer( [(\"embarked_ohe\", OneHotEncoder(categories='auto'), ['Embarked'])], \n",
    "                         remainder='passthrough')\n",
    "\n",
    "# Etapa de escalado de atributos al rango [0,1]\n",
    "min_max_scaler = MinMaxScaler()\n",
    "\n",
    "# Etapa de regresión\n",
    "lin = LinearRegression()\n",
    "\n",
    "# Creación del pipeline\n",
    "pipe = Pipeline([('ohe', ohe), ('sca', min_max_scaler), ('reg', lin)])\n",
    "\n",
    "# Entranamiento del pipeline\n",
    "pipe.fit(train_X, train_y)\n",
    "\n",
    "# Evaluación R^2 del pipeline\n",
    "print('R^2:', pipe.score(test_X, test_y))\n",
    "\n",
    "# Uso del modelo y evaluación MSE\n",
    "pred = pipe.predict(test_X)\n",
    "print(pred)\n",
    "print('MSE:', mean_squared_error(test_y, pred))\n",
    "print(\"MAE:\", mean_absolute_error(test_y, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Centros de los clústeres:\n",
      " [[ 1.22124533e-15  5.39083558e-02  9.46091644e-01 -2.60902411e-15\n",
      "   7.77628032e-01  8.49056604e-01  3.75477998e-01  1.11051213e-01\n",
      "   6.01976640e-02  3.85185852e-02]\n",
      " [ 3.33066907e-16  3.79146919e-02  9.62085308e-01  9.90521327e-01\n",
      "   4.95260664e-01  3.27014218e-01  3.43576883e-01  9.95260664e-02\n",
      "   9.47867299e-02  7.78150129e-02]\n",
      " [ 1.00000000e+00 -9.02056208e-17  1.22124533e-15  6.07692308e-01\n",
      "   3.73076923e-01  5.30769231e-01  3.81939799e-01  8.46153846e-02\n",
      "   6.92307692e-02  1.33306411e-01]]\n",
      "silhouette_score: 0.4036033588295353\n",
      "calinski_harabasz: 369.21898121397436\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score, calinski_harabasz_score\n",
    "\n",
    "titanic = pd.read_csv('../../data/Cap5/titanic_ml.csv')\n",
    "\n",
    "# Etapa de one hot encoding\n",
    "ohe = ColumnTransformer( [(\"embarked_ohe\", OneHotEncoder(categories='auto'), ['Embarked'])], \n",
    "                         remainder='passthrough')\n",
    "\n",
    "# Etapa de escalado en rango [0,1]\n",
    "sca = MinMaxScaler()\n",
    "\n",
    "# Etapa de clustering\n",
    "clu = KMeans(n_clusters=3)\n",
    "\n",
    "# Creación del pipeline\n",
    "pipe = Pipeline([('ohe', ohe), ('sca', sca), ('clu',clu)])\n",
    "\n",
    "# Entrenamiento del pipeline\n",
    "pipe.fit(titanic)\n",
    "print(\"Centros de los clústeres:\\n\", pipe.named_steps['clu'].cluster_centers_)\n",
    "\n",
    "# Evaluación de los clústeres\n",
    "print('silhouette_score:', silhouette_score(titanic_2, pipe.named_steps['clu'].labels_))\n",
    "print('calinski_harabasz:', calinski_harabasz_score(titanic_2, pipe.named_steps['clu'].labels_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Persistencia de modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Centros de los clústeres:\n",
      " [[ 1.00000000e+00 -9.02056208e-17  1.22124533e-15  6.07692308e-01\n",
      "   3.73076923e-01  5.30769231e-01  3.81939799e-01  8.46153846e-02\n",
      "   6.92307692e-02  1.33306411e-01]\n",
      " [ 1.22124533e-15  5.39083558e-02  9.46091644e-01 -2.60902411e-15\n",
      "   7.77628032e-01  8.49056604e-01  3.75477998e-01  1.11051213e-01\n",
      "   6.01976640e-02  3.85185852e-02]\n",
      " [ 3.33066907e-16  3.79146919e-02  9.62085308e-01  9.90521327e-01\n",
      "   4.95260664e-01  3.27014218e-01  3.43576883e-01  9.95260664e-02\n",
      "   9.47867299e-02  7.78150129e-02]]\n",
      "silhouette_score: 0.4036033588295353\n",
      "calinski_harabasz: 369.2189812139743\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['../../data/Cap5/kmeans.pkl']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Salvar un modelo de clustering k-means\n",
    "import joblib\n",
    "\n",
    "titanic = pd.read_csv('../../data/Cap5/titanic_ml.csv')\n",
    "\n",
    "ohe = ColumnTransformer( [(\"embarked_ohe\", OneHotEncoder(categories='auto'), ['Embarked'])], \n",
    "                         remainder='passthrough')\n",
    "titanic_1 = ohe.fit_transform(titanic)\n",
    "min_max_scaler = MinMaxScaler()\n",
    "titanic_2 = min_max_scaler.fit_transform(titanic_1)\n",
    "\n",
    "clu = KMeans(n_clusters=3)\n",
    "clu.fit(titanic_2)\n",
    "\n",
    "print(\"Centros de los clústeres:\\n\", clu.cluster_centers_)\n",
    "print('silhouette_score:', silhouette_score(titanic_2, clu.labels_))\n",
    "print('calinski_harabasz:', calinski_harabasz_score(titanic_2, clu.labels_))\n",
    "\n",
    "joblib.dump(clu, '../../data/Cap5/kmeans.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Centros de los clústeres:\n",
      " [[ 1.00000000e+00 -9.02056208e-17  1.22124533e-15  6.07692308e-01\n",
      "   3.73076923e-01  5.30769231e-01  3.81939799e-01  8.46153846e-02\n",
      "   6.92307692e-02  1.33306411e-01]\n",
      " [ 1.22124533e-15  5.39083558e-02  9.46091644e-01 -2.60902411e-15\n",
      "   7.77628032e-01  8.49056604e-01  3.75477998e-01  1.11051213e-01\n",
      "   6.01976640e-02  3.85185852e-02]\n",
      " [ 3.33066907e-16  3.79146919e-02  9.62085308e-01  9.90521327e-01\n",
      "   4.95260664e-01  3.27014218e-01  3.43576883e-01  9.95260664e-02\n",
      "   9.47867299e-02  7.78150129e-02]]\n",
      "silhouette_score: 0.4036033588295353\n",
      "calinski_harabasz: 369.2189812139743\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.73984874, 0.31789029, 1.31150832],\n",
       "       [0.77530662, 2.0626726 , 1.52274362],\n",
       "       [1.69060722, 1.33998748, 0.62284202],\n",
       "       ...,\n",
       "       [1.6169074 , 1.53881024, 0.62174709],\n",
       "       [0.73107457, 1.88275404, 1.62637004],\n",
       "       [1.73454341, 1.37090166, 1.88829988]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cargar y utilizar un modelo de clustering k-means\n",
    "loaded_clu = joblib.load('../../data/Cap5/kmeans.pkl') \n",
    "\n",
    "print(\"Centros de los clústeres:\\n\", clu.cluster_centers_)\n",
    "print('silhouette_score:', silhouette_score(titanic_2, clu.labels_))\n",
    "print('calinski_harabasz:', calinski_harabasz_score(titanic_2, clu.labels_))\n",
    "clu.transform(titanic_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Centros de los clústeres:\n",
      " [[ 3.33066907e-16  3.79146919e-02  9.62085308e-01  9.90521327e-01\n",
      "   4.95260664e-01  3.27014218e-01  3.43576883e-01  9.95260664e-02\n",
      "   9.47867299e-02  7.78150129e-02]\n",
      " [ 1.22124533e-15  5.39083558e-02  9.46091644e-01 -2.60902411e-15\n",
      "   7.77628032e-01  8.49056604e-01  3.75477998e-01  1.11051213e-01\n",
      "   6.01976640e-02  3.85185852e-02]\n",
      " [ 1.00000000e+00 -9.02056208e-17  1.22124533e-15  6.07692308e-01\n",
      "   3.73076923e-01  5.30769231e-01  3.81939799e-01  8.46153846e-02\n",
      "   6.92307692e-02  1.33306411e-01]]\n",
      "silhouette_score: 0.4036033588295353\n",
      "calinski_harabasz: 369.21898121397436\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['../../data/Cap5/kmeans_pipeline.pkl']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Salvar pipeline de clustering k-means\n",
    "titanic = pd.read_csv('../../data/Cap5/titanic_ml.csv')\n",
    "\n",
    "ohe = ColumnTransformer( [(\"embarked_ohe\", OneHotEncoder(categories='auto'), ['Embarked'])], \n",
    "                         remainder='passthrough')\n",
    "sca = MinMaxScaler()\n",
    "clu = KMeans(n_clusters=3)\n",
    "\n",
    "pipe = Pipeline([('ohe', ohe), ('sca', sca), ('clu',clu)])\n",
    "pipe.fit(titanic)\n",
    "\n",
    "print(\"Centros de los clústeres:\\n\", pipe.named_steps['clu'].cluster_centers_)\n",
    "print('silhouette_score:', silhouette_score(titanic_2, pipe.named_steps['clu'].labels_))\n",
    "print('calinski_harabasz:', calinski_harabasz_score(titanic_2, pipe.named_steps['clu'].labels_))\n",
    "\n",
    "joblib.dump(pipe, '../../data/Cap5/kmeans_pipeline.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Centros de los clústeres:\n",
      " [[ 3.33066907e-16  3.79146919e-02  9.62085308e-01  9.90521327e-01\n",
      "   4.95260664e-01  3.27014218e-01  3.43576883e-01  9.95260664e-02\n",
      "   9.47867299e-02  7.78150129e-02]\n",
      " [ 1.22124533e-15  5.39083558e-02  9.46091644e-01 -2.60902411e-15\n",
      "   7.77628032e-01  8.49056604e-01  3.75477998e-01  1.11051213e-01\n",
      "   6.01976640e-02  3.85185852e-02]\n",
      " [ 1.00000000e+00 -9.02056208e-17  1.22124533e-15  6.07692308e-01\n",
      "   3.73076923e-01  5.30769231e-01  3.81939799e-01  8.46153846e-02\n",
      "   6.92307692e-02  1.33306411e-01]]\n",
      "silhouette_score: 0.4036033588295353\n",
      "calinski_harabasz: 369.21898121397436\n"
     ]
    }
   ],
   "source": [
    "# Cargar y utilizar un pipeline de clustering k-means\n",
    "loaded_pipe = joblib.load('../../data/Cap5/kmeans_pipeline.pkl') \n",
    "\n",
    "print(\"Centros de los clústeres:\\n\", loaded_pipe.named_steps['clu'].cluster_centers_)\n",
    "print('silhouette_score:', silhouette_score(titanic_2, loaded_pipe.named_steps['clu'].labels_))\n",
    "print('calinski_harabasz:', calinski_harabasz_score(titanic_2, loaded_pipe.named_steps['clu'].labels_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimización de hiperparámetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
    "from sklearn import svm\n",
    "import pandas as pd\n",
    "\n",
    "# División en train (80%) y test (20%) para clasificación, con clase 'Survived'\n",
    "titanic = pd.read_csv('../../data/Cap5/titanic_ml.csv')\n",
    "train_X, train_y, test_X, test_y = split_label(titanic, 0.2, 'Survived')\n",
    "\n",
    "ohe = ColumnTransformer( [(\"embarked_ohe\", OneHotEncoder(categories='auto'), ['Embarked'])], \n",
    "                         remainder='passthrough')\n",
    "train_X_1 = ohe.fit_transform(train_X)\n",
    "\n",
    "min_max_scaler = MinMaxScaler()\n",
    "train_X_2 = min_max_scaler.fit_transform(train_X_1)\n",
    "\n",
    "svc = svm.SVC(gamma='scale')\n",
    "\n",
    "parameters = {'kernel': ['linear', 'rbf'], 'C':[1,2] }\n",
    "clf = GridSearchCV(svc, parameters, n_jobs=4, cv=3)\n",
    "clf.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(clf.best_params_)\n",
    "print(clf.best_score_)\n",
    "print(clf.best_estimator_)\n",
    "\n",
    "print(clf.score(test_X, test_y))\n",
    "clf.predict(test_X)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
